{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install https://github.com/acpopescu/bitsandbytes/releases/download/v0.37.2-win.1/bitsandbytes-0.37.2-py3-none-any.whl\n",
    "# pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/torch_stable.html\n",
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
    "# pip install bitsandbytes-windows\n",
    "# pip install torch transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cemticsai\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "# torch.cuda.is_available()\n",
    "# torch.cuda.device_count()\n",
    "# torch.cuda.current_device()\n",
    "# torch.cuda.get_device_name(0)\n",
    "# torch.cuda.get_device_name(1)\n",
    "\n",
    "# use an A100 on Colab Pro (or any system with >30GB VRAM on your own machine) to load this in bf16\n",
    "# if not available, use a GPU with minimum 20GB VRAM to load this in 8bit, or with minimum 12GB of VRAM to load in 4bit\n",
    "# on Colab, works with a V100 but crashes on a T4\n",
    "\n",
    "# downloading the model and then loading it to memory step takes around 10 minutes the first time. Be patient :)\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def clear_ram_cache():\n",
    "    psutil.virtual_memory().available  # This can help free up some cached memory\n",
    "\n",
    "# Call the function to attempt to clear RAM cache\n",
    "clear_ram_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "df = pd.read_excel(r\"C:\\Users\\cemticsai\\Documents\\Projects\\text2sql\\SQL code\\SQL data\\demo data\\clutser_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(355467, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer', 'sitename', 'segment', 'churn_tag', 'voip_calls_count',\n",
       "       'total_data_volume_mb', 'total_revenue', 'voice_calls_count',\n",
       "       'segment_churn_tag', 'voip_consitant_tag', 'work_pattern',\n",
       "       'voip1_user_tag', 'ppsf_tag', 'work_from_home_tag', 'data_user_tag',\n",
       "       'voip2_user_tag', 'wifi_user_tag_new', 'y_pred',\n",
       "       'per_difference_outgoing_calls', 'per_difference_fb_act_hour',\n",
       "       'outgoingcallsdormancydays', 'per_difference_data_volume',\n",
       "       'recharge_recency', 'bonus_frequency_last_3_months',\n",
       "       'paidvideouserstag', 'news_financial_rider_users_tag', 'throughput',\n",
       "       'video_user'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355467"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data and load it to Database\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# Connect to the database (or create it if it doesn't exist)\n",
    "conn = sqlite3.connect('democustomerdata.sqlite')\n",
    "c = conn.cursor()\n",
    "\n",
    "# Create the table\n",
    "c.execute('''CREATE TABLE democustomerdata (\n",
    "    customer VARCHAR(5) NOT NULL,\n",
    "    sitename VARCHAR(10) NOT NULL,\n",
    "    segment VARCHAR(2) CHECK (segment IN ('MV', 'HV')) ,\n",
    "    churn_tag VARCHAR(20) CHECK(churn_tag IN(\"Degrowth\",\"Consistent\")),\n",
    "    voip_calls_count FLOAT,\n",
    "    total_data_volume_mb FLOAT,\n",
    "    total_revenue FLOAT,\n",
    "    voice_calls_count FLOAT,\n",
    "    segment_churn_tag VARCHAR(30) CHECK(segment_churn_tag IN(\"HV_Consistent_New\",\"MV_Degrowth_New\",\"MV_Consistent_New\",\"HV_Degrowth_New\")),\n",
    "    voip_consistent_tag VARCHAR(30)CHECK (voip_consistent_tag IN(\"Zero\",\"Consitent  users\",\"in Consitent  users\",\"recent\")),\n",
    "    work_pattern VARCHAR(30)CHECK( work_pattern IN(\"Inconsistent Worker\",\"Consistent Workers\",\"Home Bound\",\"Others\")),\n",
    "    voip1_user_tag VARCHAR(20),\n",
    "    ppsf_tag VARCHAR(10)CHECK(ppsf_tag IN(\"Low\",\"Medium\",\"High\",\"Very High\",\"NA\")),\n",
    "    work_from_home_tag VARCHAR(15) CHECK(work_from_home_tag IN (\"Work from Office\",\"Home bound\",\"Work from Home\",\"Other\")),\n",
    "    data_user_tag VARCHAR(10) CHECK(data_user_tag IN(\"very_high\",\"high\",\"low\",\"very_low\",\"mid\")),\n",
    "    voip2_user_tag VARCHAR(20),\n",
    "    wifi_user_tag_new VARCHAR(10) CHECK(wifi_user_tag_new IN(\"no_wifi\",\"Med_prob_wifi\")),\n",
    "    y_pred VARCHAR(2)  CHECK( y_pred IN(\"0\",\"1\")),\n",
    "    per_difference_outgoing_calls FLOAT,\n",
    "    per_difference_fb_act_hour FLOAT,\n",
    "    outgoingcallsdormancydays FLOAT,\n",
    "    per_difference_data_volume FLOAT,\n",
    "    recharge_recency VARCHAR(2)  CHECK( recharge_recency IN(\"0\",\"1\")),\n",
    "    bonus_frequency_last_3_months VARCHAR(2)  CHECK(bonus_frequency_last_3_months IN(\"0\",\"1\")),\n",
    "    paidvideouserstag VARCHAR(3) CHECK(paidvideouserstag IN(\"No\",\"Yes\")),\n",
    "    news_financial_rider_users_tag VARCHAR(3)CHECK(news_financial_rider_users_tag IN(\"0\",\"1\")) ,\n",
    "    throughput VARCHAR(20)CHECK(throughput IN(\"Low\",\"Medium\",\"High\",\"Very High\")),\n",
    "    video_user VARCHAR(20) CHECK(video_user IN(\"No video user\",\"Paid_video_user\",\"video_user\"))\n",
    ");''')\n",
    "\n",
    "# Commit the changes and close the connection\n",
    "conn.commit()\n",
    "\n",
    "df.to_sql('democustomerdata', conn, if_exists='replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "CUDA SETUP: CUDA runtime path found: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.7\\bin\\cudart64_110.dll\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary c:\\Users\\cemticsai\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda117.dll...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cemticsai\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:141: UserWarning: C:\\Users\\cemticsai\\anaconda3\\envs\\torchgpu did not contain cudart64_110.dll as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "c:\\Users\\cemticsai\\anaconda3\\envs\\torchgpu\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:141: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {WindowsPath('C:/Users/cemticsai/anaconda3/envs/torchgpu/Library/mingw-w64/bin'), WindowsPath('C:/Users/cemticsai/anaconda3/envs/torchgpu/Library/usr/bin'), WindowsPath('C:/Users/cemticsai/anaconda3/envs/torchgpu/bin')}\n",
      "  warn(msg)\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:21<00:00,  5.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# Fetching model\n",
    "\n",
    "model_name = r\"C:\\Users\\cemticsai\\Documents\\Projects\\text2sql\\SQL code\\SQL project\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    # torch_dtype=torch.bfloat16,\n",
    "    load_in_8bit=True,\n",
    "    #load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    "    use_cache=True,\n",
    "    offload_folder=\"offload\", torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2sql(question):\n",
    "  prompt = \"\"\"### Instructions:\n",
    "    Your task is convert a question into a SQL query, given a Postgres database schema.\n",
    "\n",
    "    ### Input:\n",
    "    Generate a SQL query that answers the question `{question}`.\n",
    "    This query will run on a database whose schema is represented in this string:\n",
    "\n",
    "  CREATE TABLE democustomerdata (\n",
    "      customer VARCHAR(5) NOT NULL,\n",
    "      sitename VARCHAR(10) NOT NULL,\n",
    "      segment VARCHAR(2) CHECK (segment IN ('MV', 'HV')) ,\n",
    "      churn_tag VARCHAR(20) CHECK(churn_tag IN(\"Degrowth\",\"Consistent\")),\n",
    "      voip_calls_count INT,\n",
    "      total_data_volume_mb INT,\n",
    "      total_revenue INT,\n",
    "      voice_calls_count INT,\n",
    "      segment_churn_tag VARCHAR(30) CHECK(segment_churn_tag IN(\"HV_Consistent_New\",\"MV_Degrowth_New\",\"MV_Consistent_New\",\"HV_Degrowth_New\")),\n",
    "      voip_consistent_tag VARCHAR(30)CHECK (voip_consistent_tag IN(\"Zero\",\"Consitent  users\",\"in Consitent  users\",\"recent\")),\n",
    "      work_pattern VARCHAR(30)CHECK( work_pattern IN(\"Inconsistent Worker\",\"Consistent Workers\",\"Home Bound\",\"Others\")),\n",
    "      voip1_user_tag VARCHAR(20)CHECK(voip_user_tag  IN (\"voip_user\",\"not voip user\")),\n",
    "      ppsf_tag VARCHAR(10)CHECK(ppsf_tag IN(\"Low\",\"Medium\",\"High\",\"Very High\",\"NA\")),\n",
    "      work_from_home_tag VARCHAR(15) CHECK(work_from_home_tag IN (\"Work from Office\",\"Home bound\",\"Work from Home\",\"Other\")),\n",
    "      data_user_tag VARCHAR(10) CHECK(data_user_tag IN(\"very_high\",\"high\",\"low\",\"very_low\",\"mid\")),\n",
    "      voip2_user_tag VARCHAR(20) CHECK(voip_user_tag IN(\"No_Voip_User\",\"Voip_User\",\"Recent_Voip_user\")),\n",
    "      wifi_user_tag_new VARCHAR(10) CHECK(wifi_user_tag_new IN(\"no_wifi\",\"Med_prob_wifi\")),\n",
    "      y_pred VARCHAR(2)  CHECK( y_pred IN(\"0\",\"1\")),\n",
    "      per_difference_outgoing_calls INT,\n",
    "      per_difference_fb_act_hour INT,\n",
    "      outgoingcallsdormancydays INT,\n",
    "      per_difference_data_volume INT,\n",
    "      recharge_recency VARCHAR(2)  CHECK( recharge_recency IN(\"0\",\"1\")),\n",
    "      bonus_frequency_last_3_months VARCHAR(2)  CHECK(bonus_frequency_last_3_months IN(\"0\",\"1\")),\n",
    "      paidvideouserstag VARCHAR(3) CHECK(paidvideouserstag IN(\"No\",\"Yes\")),\n",
    "      news_financial_rider_users_tag VARCHAR(3)CHECK(news_financial_rider_users_tag IN(\"0\",\"1\")) ,\n",
    "      throughput VARCHAR(20)CHECK(throughput IN(\"Low\",\"Medium\",\"High\",\"Very High\")),\n",
    "      video_user VARCHAR(20) CHECK(video_user IN(\"No video user\",\"Paid_video_user\",\"video_user\"))\n",
    "  );\n",
    "\n",
    "\n",
    "    ### Response:\n",
    "    Based on your instructions, here is the SQL query I have generated to answer the question `{question}`:\n",
    "    ```sql\n",
    "    \"\"\".format(question=question)\n",
    "\n",
    "\n",
    "\n",
    "  ##################################\n",
    "\n",
    "  eos_token_id = tokenizer.convert_tokens_to_ids([\"```\"])[0]\n",
    "  # excruciatingly slow on an V100 with 4bit quantization\n",
    "  # takes around 1-2 minutes per query\n",
    "  # on a single A100 40GB, takes ~10-20 seconds\n",
    "  # torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "  inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "  generated_ids = model.generate(\n",
    "      **inputs,\n",
    "      num_return_sequences=1,\n",
    "      eos_token_id=eos_token_id,\n",
    "      pad_token_id=eos_token_id,\n",
    "      max_new_tokens=200,\n",
    "      do_sample=False,\n",
    "      num_beams=1\n",
    "  )\n",
    "\n",
    "  outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "  t= outputs[0].split(\"```sql\")[-1].split(\"```\")[0].split(\";\")[0].strip() + \";\"\n",
    "  print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT count(*) AS count_of_paid_video_customers_with_dormancy_greater_than_8\n",
      "     FROM   democustomerdata\n",
      "     WHERE  democustomerdata.paidvideouserstag = 'Yes'\n",
      "        AND democustomerdata.outgoingcallsdormancydays > 8;\n"
     ]
    }
   ],
   "source": [
    "# Run Query here\n",
    "\n",
    "text2sql(\"show me count of Paid Video customers with dormancy greater than 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10308,)\n"
     ]
    }
   ],
   "source": [
    "# Get Data\n",
    "\n",
    "c.execute('''SELECT COUNT(*) AS customer_count\n",
    "FROM democustomerdata\n",
    "WHERE video_user = 'Paid_video_user' AND outgoingcallsdormancydays > 8;\n",
    "           ''')\n",
    "\n",
    "for row in c.fetchall():\n",
    "     print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
